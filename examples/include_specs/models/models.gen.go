// Code generated by pggen DO NOT EDIT.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"github.com/ethanpailes/pgtypes"
	"github.com/opendoor/pggen"
	"github.com/opendoor/pggen/include"
	"github.com/opendoor/pggen/unstable"
	"strings"
	"sync"
)

// PGClient wraps either a 'sql.DB' or a 'sql.Tx'. All pggen-generated
// database access methods for this package are attached to it.
type PGClient struct {
	impl       pgClientImpl
	topLevelDB pggen.DBConn

	errorConverter func(error) error

	// These column indexes are used at run time to enable us to 'SELECT *' against
	// a table that has the same columns in a different order from the ones that we
	// saw in the table we used to generate code. This means that you don't have to worry
	// about migrations merging in a slightly different order than their timestamps have
	// breaking 'SELECT *'.
	rwlockForGrandparent    sync.RWMutex
	colIdxTabForGrandparent []int
	rwlockForParent         sync.RWMutex
	colIdxTabForParent      []int
	rwlockForChild          sync.RWMutex
	colIdxTabForChild       []int
}

// bogus usage so we can compile with no tables configured
var _ = sync.RWMutex{}

// NewPGClient creates a new PGClient out of a '*sql.DB' or a
// custom wrapper around a db connection.
//
// If you provide your own wrapper around a '*sql.DB' for logging or
// custom tracing, you MUST forward all calls to an underlying '*sql.DB'
// member of your wrapper.
//
// If the DBConn passed into NewPGClient implements an ErrorConverter
// method which returns a func(error) error, the result of calling the
// ErrorConverter method will be called on every error that the generated
// code returns right before the error is returned. If ErrorConverter
// returns nil or is not present, it will default to the identity function.
func NewPGClient(conn pggen.DBConn) *PGClient {
	client := PGClient{
		topLevelDB: conn,
	}
	client.impl = pgClientImpl{
		db:     conn,
		client: &client,
	}

	// extract the optional error converter routine
	ec, ok := conn.(interface {
		ErrorConverter() func(error) error
	})
	if ok {
		client.errorConverter = ec.ErrorConverter()
	}
	if client.errorConverter == nil {
		client.errorConverter = func(err error) error { return err }
	}

	return &client
}

func (p *PGClient) Handle() pggen.DBHandle {
	return p.topLevelDB
}

func (p *PGClient) BeginTx(ctx context.Context, opts *sql.TxOptions) (*TxPGClient, error) {
	tx, err := p.topLevelDB.BeginTx(ctx, opts)
	if err != nil {
		return nil, p.errorConverter(err)
	}

	return &TxPGClient{
		impl: pgClientImpl{
			db:     tx,
			client: p,
		},
	}, nil
}

func (p *PGClient) Conn(ctx context.Context) (*ConnPGClient, error) {
	conn, err := p.topLevelDB.Conn(ctx)
	if err != nil {
		return nil, p.errorConverter(err)
	}

	return &ConnPGClient{impl: pgClientImpl{db: conn, client: p}}, nil
}

// A postgres client that operates within a transaction. Supports all the same
// generated methods that PGClient does.
type TxPGClient struct {
	impl pgClientImpl
}

func (tx *TxPGClient) Handle() pggen.DBHandle {
	return tx.impl.db.(*sql.Tx)
}

func (tx *TxPGClient) Rollback() error {
	return tx.impl.db.(*sql.Tx).Rollback()
}

func (tx *TxPGClient) Commit() error {
	return tx.impl.db.(*sql.Tx).Commit()
}

type ConnPGClient struct {
	impl pgClientImpl
}

func (conn *ConnPGClient) Close() error {
	return conn.impl.db.(*sql.Conn).Close()
}

func (conn *ConnPGClient) Handle() pggen.DBHandle {
	return conn.impl.db
}

// A database client that can wrap either a direct database connection or a transaction
type pgClientImpl struct {
	db pggen.DBHandle
	// a reference back to the owning PGClient so we can always get at the resolver tables
	client *PGClient
}

func (p *PGClient) GetGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Grandparent, error) {
	return p.impl.getGrandparent(ctx, id)
}
func (tx *TxPGClient) GetGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Grandparent, error) {
	return tx.impl.getGrandparent(ctx, id)
}
func (conn *ConnPGClient) GetGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Grandparent, error) {
	return conn.impl.getGrandparent(ctx, id)
}
func (p *pgClientImpl) getGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Grandparent, error) {
	values, err := p.listGrandparent(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListGrandparent always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Grandparent, err error) {
	return p.impl.listGrandparent(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Grandparent, err error) {
	return tx.impl.listGrandparent(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Grandparent, err error) {
	return conn.impl.listGrandparent(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listGrandparent(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Grandparent, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Grandparent{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM grandparents WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Grandparent, 0, len(ids))
	for rows.Next() {
		var value Grandparent
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetGrandparent: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListGrandparent: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Grandparent into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertGrandparent(
	ctx context.Context,
	value *Grandparent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertGrandparent(ctx, value, opts...)
}

// Insert a Grandparent into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertGrandparent(
	ctx context.Context,
	value *Grandparent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertGrandparent(ctx, value, opts...)
}

// Insert a Grandparent into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertGrandparent(
	ctx context.Context,
	value *Grandparent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertGrandparent(ctx, value, opts...)
}

// Insert a Grandparent into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertGrandparent(
	ctx context.Context,
	value *Grandparent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertGrandparent(ctx, []Grandparent{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Grandparent: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Grandparent. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertGrandparent(ctx, values, opts...)
}

// Insert a list of Grandparent. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertGrandparent(ctx, values, opts...)
}

// Insert a list of Grandparent. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertGrandparent(ctx, values, opts...)
}

// Insert a list of Grandparent. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForGrandparent)
	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(GrandparentIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(GrandparentNameFieldIndex) {
			args = append(args, v.Name)
		}
		if !defaultFields.Test(GrandparentFavoriteGrandkidIdFieldIndex) {
			args = append(args, v.FavoriteGrandkidId)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`grandparents`,
		fieldsForGrandparent,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	GrandparentIdFieldIndex                 int = 0
	GrandparentNameFieldIndex               int = 1
	GrandparentFavoriteGrandkidIdFieldIndex int = 2
	GrandparentMaxFieldIndex                int = (3 - 1)
)

// A field set saying that all fields in Grandparent should be updated.
// For use as a 'fieldMask' parameter
var GrandparentAllFields pggen.FieldSet = pggen.NewFieldSetFilled(3)

var defaultableColsForGrandparent = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(GrandparentMaxFieldIndex)
	fs.Set(GrandparentIdFieldIndex, true)
	return fs
}()

var fieldsForGrandparent []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: GrandparentIdFieldIndex},
	{name: `name`, idx: GrandparentNameFieldIndex},
	{name: `favorite_grandkid_id`, idx: GrandparentFavoriteGrandkidIdFieldIndex},
}

// Update a Grandparent. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateGrandparent(
	ctx context.Context,
	value *Grandparent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateGrandparent(ctx, value, fieldMask, opts...)
}

// Update a Grandparent. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateGrandparent(
	ctx context.Context,
	value *Grandparent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateGrandparent(ctx, value, fieldMask, opts...)
}

// Update a Grandparent. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateGrandparent(
	ctx context.Context,
	value *Grandparent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateGrandparent(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateGrandparent(
	ctx context.Context,
	value *Grandparent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(GrandparentIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'grandparents'`))
	}

	updateStmt := genUpdateStmt(
		`grandparents`,
		"id",
		fieldsForGrandparent,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 3)
	if fieldMask.Test(GrandparentIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(GrandparentNameFieldIndex) {
		args = append(args, value.Name)
	}
	if fieldMask.Test(GrandparentFavoriteGrandkidIdFieldIndex) {
		args = append(args, value.FavoriteGrandkidId)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Grandparent value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertGrandparent(
	ctx context.Context,
	value *Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertGrandparent(ctx, []Grandparent{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Grandparent value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertGrandparent(
	ctx context.Context,
	value *Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertGrandparent(ctx, []Grandparent{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Grandparent value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertGrandparent(
	ctx context.Context,
	value *Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertGrandparent(ctx, []Grandparent{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Grandparent values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertGrandparent(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Grandparent values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertGrandparent(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Grandparent values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertGrandparent(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertGrandparent(
	ctx context.Context,
	values []Grandparent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForGrandparent)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`grandparents`,
		fieldsForGrandparent,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(GrandparentIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(GrandparentIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 3)
		updateExprs := make([]string, 0, 3)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(GrandparentNameFieldIndex) {
			updateCols = append(updateCols, `name`)
			updateExprs = append(updateExprs, `excluded.name`)
		}
		if fieldMask.Test(GrandparentFavoriteGrandkidIdFieldIndex) {
			updateCols = append(updateCols, `favorite_grandkid_id`)
			updateExprs = append(updateExprs, `excluded.favorite_grandkid_id`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(GrandparentIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(GrandparentNameFieldIndex) {
			args = append(args, v.Name)
		}
		if !defaultFields.Test(GrandparentFavoriteGrandkidIdFieldIndex) {
			args = append(args, v.FavoriteGrandkidId)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteGrandparent(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteGrandparent(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteGrandparent(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteGrandparent(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteGrandparent(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteGrandparent(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteGrandparent(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteGrandparent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM grandparents WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteGrandparent: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var GrandparentAllIncludes *include.Spec = include.Must(include.Parse(
	`grandparents.{favorite_grandkid->children.{darling_grandparents->grandparents,parents.{children,grandparents}},parents}`,
))

func (p *PGClient) GrandparentFillIncludes(
	ctx context.Context,
	rec *Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateGrandparentBulkFillIncludes(ctx, []*Grandparent{rec}, includes)
}
func (tx *TxPGClient) GrandparentFillIncludes(
	ctx context.Context,
	rec *Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateGrandparentBulkFillIncludes(ctx, []*Grandparent{rec}, includes)
}
func (conn *ConnPGClient) GrandparentFillIncludes(
	ctx context.Context,
	rec *Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateGrandparentBulkFillIncludes(ctx, []*Grandparent{rec}, includes)
}

func (p *PGClient) GrandparentBulkFillIncludes(
	ctx context.Context,
	recs []*Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateGrandparentBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) GrandparentBulkFillIncludes(
	ctx context.Context,
	recs []*Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateGrandparentBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) GrandparentBulkFillIncludes(
	ctx context.Context,
	recs []*Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateGrandparentBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateGrandparentBulkFillIncludes(
	ctx context.Context,
	recs []*Grandparent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implGrandparentBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implGrandparentBulkFillIncludes(
	ctx context.Context,
	recs []*Grandparent,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `grandparents` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'grandparents', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`grandparents`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Grandparent)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Grandparent, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`grandparents`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the Parents if it is in includes
	subSpec, inIncludeSet = includes.Includes[`parents`]
	if inIncludeSet {
		err = p.privateGrandparentFillParents(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Parent, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.Parents {
				subRecs = append(subRecs, outer.Parents[i])
			}
		}

		err = p.implParentBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`favorite_grandkid`]
	if inIncludeSet {
		err = p.privateGrandparentFillParentFavoriteGrandkid(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Child, 0, len(recs))
		for _, outer := range recs {
			if outer.FavoriteGrandkid != nil {
				subRecs = append(subRecs, outer.FavoriteGrandkid)
			}
		}

		err = p.implChildBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Grandparent, fill in all the Parent
// connected to them using a single query.
func (p *pgClientImpl) privateGrandparentFillParents(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`grandparents`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Grandparent)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*Parent
	childLoadedTab, inMap := loadedRecordTab[`parents`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*Parent)
	} else {
		childIDToRecord = map[int64]*Parent{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM parents
		 WHERE "grandparent_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec Parent
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *Parent

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.GrandparentId]
		parentRec.Parents = append(parentRec.Parents, childRec)
	}

	loadedRecordTab[`parents`] = childIDToRecord

	return nil
}

// For a given set of Grandparent, fill in all the Child
// connected to them using at most one query.
func (p *pgClientImpl) privateGrandparentFillParentFavoriteGrandkid(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`grandparents`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*Grandparent)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Child
	parentLoadedTab, inMap := loadedRecordTab[`children`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Child)
	} else {
		parentIDToRecord = map[int64]*Child{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		if rec.FavoriteGrandkidId == nil {
			continue
		}
		parentID := *rec.FavoriteGrandkidId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.FavoriteGrandkid = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*Grandparent{}
	for _, rec := range childIDToRecord {
		if rec.FavoriteGrandkidId == nil {
			continue
		}
		parentID := *rec.FavoriteGrandkidId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*Grandparent{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM children
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Child
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.FavoriteGrandkid = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`children`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetParent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Parent, error) {
	return p.impl.getParent(ctx, id)
}
func (tx *TxPGClient) GetParent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Parent, error) {
	return tx.impl.getParent(ctx, id)
}
func (conn *ConnPGClient) GetParent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Parent, error) {
	return conn.impl.getParent(ctx, id)
}
func (p *pgClientImpl) getParent(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Parent, error) {
	values, err := p.listParent(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListParent always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Parent, err error) {
	return p.impl.listParent(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Parent, err error) {
	return tx.impl.listParent(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Parent, err error) {
	return conn.impl.listParent(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listParent(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Parent, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Parent{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM parents WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Parent, 0, len(ids))
	for rows.Next() {
		var value Parent
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetParent: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListParent: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Parent into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertParent(
	ctx context.Context,
	value *Parent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertParent(ctx, value, opts...)
}

// Insert a Parent into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertParent(
	ctx context.Context,
	value *Parent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertParent(ctx, value, opts...)
}

// Insert a Parent into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertParent(
	ctx context.Context,
	value *Parent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertParent(ctx, value, opts...)
}

// Insert a Parent into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertParent(
	ctx context.Context,
	value *Parent,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertParent(ctx, []Parent{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Parent: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Parent. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertParent(
	ctx context.Context,
	values []Parent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertParent(ctx, values, opts...)
}

// Insert a list of Parent. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertParent(
	ctx context.Context,
	values []Parent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertParent(ctx, values, opts...)
}

// Insert a list of Parent. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertParent(
	ctx context.Context,
	values []Parent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertParent(ctx, values, opts...)
}

// Insert a list of Parent. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertParent(
	ctx context.Context,
	values []Parent,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForParent)
	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(ParentIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(ParentGrandparentIdFieldIndex) {
			args = append(args, v.GrandparentId)
		}
		if !defaultFields.Test(ParentNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`parents`,
		fieldsForParent,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	ParentIdFieldIndex            int = 0
	ParentGrandparentIdFieldIndex int = 1
	ParentNameFieldIndex          int = 2
	ParentMaxFieldIndex           int = (3 - 1)
)

// A field set saying that all fields in Parent should be updated.
// For use as a 'fieldMask' parameter
var ParentAllFields pggen.FieldSet = pggen.NewFieldSetFilled(3)

var defaultableColsForParent = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(ParentMaxFieldIndex)
	fs.Set(ParentIdFieldIndex, true)
	return fs
}()

var fieldsForParent []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: ParentIdFieldIndex},
	{name: `grandparent_id`, idx: ParentGrandparentIdFieldIndex},
	{name: `name`, idx: ParentNameFieldIndex},
}

// Update a Parent. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateParent(
	ctx context.Context,
	value *Parent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateParent(ctx, value, fieldMask, opts...)
}

// Update a Parent. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateParent(
	ctx context.Context,
	value *Parent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateParent(ctx, value, fieldMask, opts...)
}

// Update a Parent. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateParent(
	ctx context.Context,
	value *Parent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateParent(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateParent(
	ctx context.Context,
	value *Parent,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(ParentIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'parents'`))
	}

	updateStmt := genUpdateStmt(
		`parents`,
		"id",
		fieldsForParent,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 3)
	if fieldMask.Test(ParentIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(ParentGrandparentIdFieldIndex) {
		args = append(args, value.GrandparentId)
	}
	if fieldMask.Test(ParentNameFieldIndex) {
		args = append(args, value.Name)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Parent value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertParent(
	ctx context.Context,
	value *Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertParent(ctx, []Parent{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Parent value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertParent(
	ctx context.Context,
	value *Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertParent(ctx, []Parent{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Parent value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertParent(
	ctx context.Context,
	value *Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertParent(ctx, []Parent{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Parent values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertParent(
	ctx context.Context,
	values []Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertParent(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Parent values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertParent(
	ctx context.Context,
	values []Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertParent(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Parent values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertParent(
	ctx context.Context,
	values []Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertParent(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertParent(
	ctx context.Context,
	values []Parent,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForParent)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`parents`,
		fieldsForParent,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(ParentIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(ParentIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 3)
		updateExprs := make([]string, 0, 3)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(ParentGrandparentIdFieldIndex) {
			updateCols = append(updateCols, `grandparent_id`)
			updateExprs = append(updateExprs, `excluded.grandparent_id`)
		}
		if fieldMask.Test(ParentNameFieldIndex) {
			updateCols = append(updateCols, `name`)
			updateExprs = append(updateExprs, `excluded.name`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(ParentIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(ParentGrandparentIdFieldIndex) {
			args = append(args, v.GrandparentId)
		}
		if !defaultFields.Test(ParentNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteParent(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteParent(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteParent(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteParent(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteParent(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteParent(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteParent(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteParent(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteParent(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteParent(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM parents WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteParent: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var ParentAllIncludes *include.Spec = include.Must(include.Parse(
	`parents.{children.{darling_grandparents->grandparents.{favorite_grandkid->children,parents},parents},grandparents}`,
))

func (p *PGClient) ParentFillIncludes(
	ctx context.Context,
	rec *Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateParentBulkFillIncludes(ctx, []*Parent{rec}, includes)
}
func (tx *TxPGClient) ParentFillIncludes(
	ctx context.Context,
	rec *Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateParentBulkFillIncludes(ctx, []*Parent{rec}, includes)
}
func (conn *ConnPGClient) ParentFillIncludes(
	ctx context.Context,
	rec *Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateParentBulkFillIncludes(ctx, []*Parent{rec}, includes)
}

func (p *PGClient) ParentBulkFillIncludes(
	ctx context.Context,
	recs []*Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateParentBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) ParentBulkFillIncludes(
	ctx context.Context,
	recs []*Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateParentBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) ParentBulkFillIncludes(
	ctx context.Context,
	recs []*Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateParentBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateParentBulkFillIncludes(
	ctx context.Context,
	recs []*Parent,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implParentBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implParentBulkFillIncludes(
	ctx context.Context,
	recs []*Parent,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `parents` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'parents', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`parents`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Parent)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Parent, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`parents`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the Children if it is in includes
	subSpec, inIncludeSet = includes.Includes[`children`]
	if inIncludeSet {
		err = p.privateParentFillChildren(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Child, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.Children {
				subRecs = append(subRecs, outer.Children[i])
			}
		}

		err = p.implChildBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`grandparents`]
	if inIncludeSet {
		err = p.privateParentFillParentGrandparent(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Grandparent, 0, len(recs))
		for _, outer := range recs {
			if outer.Grandparent != nil {
				subRecs = append(subRecs, outer.Grandparent)
			}
		}

		err = p.implGrandparentBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Parent, fill in all the Child
// connected to them using a single query.
func (p *pgClientImpl) privateParentFillChildren(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`parents`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Parent)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*Child
	childLoadedTab, inMap := loadedRecordTab[`children`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*Child)
	} else {
		childIDToRecord = map[int64]*Child{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM children
		 WHERE "parent_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec Child
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *Child

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.ParentId]
		parentRec.Children = append(parentRec.Children, childRec)
	}

	loadedRecordTab[`children`] = childIDToRecord

	return nil
}

// For a given set of Parent, fill in all the Grandparent
// connected to them using at most one query.
func (p *pgClientImpl) privateParentFillParentGrandparent(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`parents`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*Parent)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Grandparent
	parentLoadedTab, inMap := loadedRecordTab[`grandparents`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Grandparent)
	} else {
		parentIDToRecord = map[int64]*Grandparent{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.GrandparentId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Grandparent = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*Parent{}
	for _, rec := range childIDToRecord {
		parentID := rec.GrandparentId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*Parent{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM grandparents
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Grandparent
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Grandparent = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`grandparents`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetChild(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Child, error) {
	return p.impl.getChild(ctx, id)
}
func (tx *TxPGClient) GetChild(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Child, error) {
	return tx.impl.getChild(ctx, id)
}
func (conn *ConnPGClient) GetChild(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Child, error) {
	return conn.impl.getChild(ctx, id)
}
func (p *pgClientImpl) getChild(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Child, error) {
	values, err := p.listChild(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListChild always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Child, err error) {
	return p.impl.listChild(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Child, err error) {
	return tx.impl.listChild(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Child, err error) {
	return conn.impl.listChild(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listChild(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Child, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Child{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM children WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Child, 0, len(ids))
	for rows.Next() {
		var value Child
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetChild: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListChild: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Child into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertChild(
	ctx context.Context,
	value *Child,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertChild(ctx, value, opts...)
}

// Insert a Child into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertChild(
	ctx context.Context,
	value *Child,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertChild(ctx, value, opts...)
}

// Insert a Child into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertChild(
	ctx context.Context,
	value *Child,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertChild(ctx, value, opts...)
}

// Insert a Child into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertChild(
	ctx context.Context,
	value *Child,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertChild(ctx, []Child{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Child: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Child. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertChild(
	ctx context.Context,
	values []Child,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertChild(ctx, values, opts...)
}

// Insert a list of Child. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertChild(
	ctx context.Context,
	values []Child,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertChild(ctx, values, opts...)
}

// Insert a list of Child. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertChild(
	ctx context.Context,
	values []Child,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertChild(ctx, values, opts...)
}

// Insert a list of Child. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertChild(
	ctx context.Context,
	values []Child,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForChild)
	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(ChildIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(ChildParentIdFieldIndex) {
			args = append(args, v.ParentId)
		}
		if !defaultFields.Test(ChildNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`children`,
		fieldsForChild,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	ChildIdFieldIndex       int = 0
	ChildParentIdFieldIndex int = 1
	ChildNameFieldIndex     int = 2
	ChildMaxFieldIndex      int = (3 - 1)
)

// A field set saying that all fields in Child should be updated.
// For use as a 'fieldMask' parameter
var ChildAllFields pggen.FieldSet = pggen.NewFieldSetFilled(3)

var defaultableColsForChild = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(ChildMaxFieldIndex)
	fs.Set(ChildIdFieldIndex, true)
	return fs
}()

var fieldsForChild []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: ChildIdFieldIndex},
	{name: `parent_id`, idx: ChildParentIdFieldIndex},
	{name: `name`, idx: ChildNameFieldIndex},
}

// Update a Child. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateChild(
	ctx context.Context,
	value *Child,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateChild(ctx, value, fieldMask, opts...)
}

// Update a Child. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateChild(
	ctx context.Context,
	value *Child,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateChild(ctx, value, fieldMask, opts...)
}

// Update a Child. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateChild(
	ctx context.Context,
	value *Child,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateChild(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateChild(
	ctx context.Context,
	value *Child,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(ChildIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'children'`))
	}

	updateStmt := genUpdateStmt(
		`children`,
		"id",
		fieldsForChild,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 3)
	if fieldMask.Test(ChildIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(ChildParentIdFieldIndex) {
		args = append(args, value.ParentId)
	}
	if fieldMask.Test(ChildNameFieldIndex) {
		args = append(args, value.Name)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Child value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertChild(
	ctx context.Context,
	value *Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertChild(ctx, []Child{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Child value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertChild(
	ctx context.Context,
	value *Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertChild(ctx, []Child{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Child value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertChild(
	ctx context.Context,
	value *Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertChild(ctx, []Child{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Child values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertChild(
	ctx context.Context,
	values []Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertChild(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Child values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertChild(
	ctx context.Context,
	values []Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertChild(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Child values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertChild(
	ctx context.Context,
	values []Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertChild(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertChild(
	ctx context.Context,
	values []Child,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForChild)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`children`,
		fieldsForChild,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(ChildIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(ChildIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 3)
		updateExprs := make([]string, 0, 3)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(ChildParentIdFieldIndex) {
			updateCols = append(updateCols, `parent_id`)
			updateExprs = append(updateExprs, `excluded.parent_id`)
		}
		if fieldMask.Test(ChildNameFieldIndex) {
			updateCols = append(updateCols, `name`)
			updateExprs = append(updateExprs, `excluded.name`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(ChildIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(ChildParentIdFieldIndex) {
			args = append(args, v.ParentId)
		}
		if !defaultFields.Test(ChildNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteChild(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteChild(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteChild(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteChild(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteChild(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteChild(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteChild(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteChild(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteChild(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteChild(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM children WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteChild: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var ChildAllIncludes *include.Spec = include.Must(include.Parse(
	`children.{darling_grandparents->grandparents.{favorite_grandkid->children,parents.{children,grandparents}},parents}`,
))

func (p *PGClient) ChildFillIncludes(
	ctx context.Context,
	rec *Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateChildBulkFillIncludes(ctx, []*Child{rec}, includes)
}
func (tx *TxPGClient) ChildFillIncludes(
	ctx context.Context,
	rec *Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateChildBulkFillIncludes(ctx, []*Child{rec}, includes)
}
func (conn *ConnPGClient) ChildFillIncludes(
	ctx context.Context,
	rec *Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateChildBulkFillIncludes(ctx, []*Child{rec}, includes)
}

func (p *PGClient) ChildBulkFillIncludes(
	ctx context.Context,
	recs []*Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateChildBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) ChildBulkFillIncludes(
	ctx context.Context,
	recs []*Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateChildBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) ChildBulkFillIncludes(
	ctx context.Context,
	recs []*Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateChildBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateChildBulkFillIncludes(
	ctx context.Context,
	recs []*Child,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implChildBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implChildBulkFillIncludes(
	ctx context.Context,
	recs []*Child,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `children` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'children', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`children`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Child)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Child, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`children`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the Grandparents if it is in includes
	subSpec, inIncludeSet = includes.Includes[`darling_grandparents`]
	if inIncludeSet {
		err = p.privateChildFillDarlingGrandparents(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Grandparent, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.DarlingGrandparents {
				if outer.DarlingGrandparents[i] == nil {
					continue
				}
				subRecs = append(subRecs, outer.DarlingGrandparents[i])
			}
		}

		err = p.implGrandparentBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`parents`]
	if inIncludeSet {
		err = p.privateChildFillParentParent(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Parent, 0, len(recs))
		for _, outer := range recs {
			if outer.Parent != nil {
				subRecs = append(subRecs, outer.Parent)
			}
		}

		err = p.implParentBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Child, fill in all the Grandparent
// connected to them using a single query.
func (p *pgClientImpl) privateChildFillDarlingGrandparents(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`children`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Child)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*Grandparent
	childLoadedTab, inMap := loadedRecordTab[`grandparents`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*Grandparent)
	} else {
		childIDToRecord = map[int64]*Grandparent{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM grandparents
		 WHERE "favorite_grandkid_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec Grandparent
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *Grandparent

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		// we know that the foreign key can't be null because of the SQL query
		parentRec := parentIDToRecord[*childRec.FavoriteGrandkidId]
		parentRec.DarlingGrandparents = append(parentRec.DarlingGrandparents, childRec)
	}

	loadedRecordTab[`grandparents`] = childIDToRecord

	return nil
}

// For a given set of Child, fill in all the Parent
// connected to them using at most one query.
func (p *pgClientImpl) privateChildFillParentParent(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`children`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*Child)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Parent
	parentLoadedTab, inMap := loadedRecordTab[`parents`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Parent)
	} else {
		parentIDToRecord = map[int64]*Parent{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.ParentId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Parent = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*Child{}
	for _, rec := range childIDToRecord {
		parentID := rec.ParentId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*Child{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM parents
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Parent
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Parent = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`parents`] = parentIDToRecord

	return nil
}

type DBQueries interface {
	//
	// automatic CRUD methods
	//

	// Grandparent methods
	GetGrandparent(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Grandparent, error)
	ListGrandparent(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Grandparent, error)
	InsertGrandparent(ctx context.Context, value *Grandparent, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertGrandparent(ctx context.Context, values []Grandparent, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateGrandparent(ctx context.Context, value *Grandparent, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertGrandparent(ctx context.Context, value *Grandparent, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertGrandparent(ctx context.Context, values []Grandparent, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteGrandparent(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteGrandparent(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	GrandparentFillIncludes(ctx context.Context, rec *Grandparent, includes *include.Spec, opts ...pggen.IncludeOpt) error
	GrandparentBulkFillIncludes(ctx context.Context, recs []*Grandparent, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// Parent methods
	GetParent(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Parent, error)
	ListParent(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Parent, error)
	InsertParent(ctx context.Context, value *Parent, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertParent(ctx context.Context, values []Parent, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateParent(ctx context.Context, value *Parent, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertParent(ctx context.Context, value *Parent, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertParent(ctx context.Context, values []Parent, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteParent(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteParent(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	ParentFillIncludes(ctx context.Context, rec *Parent, includes *include.Spec, opts ...pggen.IncludeOpt) error
	ParentBulkFillIncludes(ctx context.Context, recs []*Parent, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// Child methods
	GetChild(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Child, error)
	ListChild(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Child, error)
	InsertChild(ctx context.Context, value *Child, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertChild(ctx context.Context, values []Child, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateChild(ctx context.Context, value *Child, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertChild(ctx context.Context, value *Child, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertChild(ctx context.Context, values []Child, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteChild(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteChild(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	ChildFillIncludes(ctx context.Context, rec *Child, includes *include.Spec, opts ...pggen.IncludeOpt) error
	ChildBulkFillIncludes(ctx context.Context, recs []*Child, includes *include.Spec, opts ...pggen.IncludeOpt) error

	//
	// query methods
	//

	//
	// stored function methods
	//

	//
	// stmt methods
	//

}

type Parent struct {
	Id            int64    `gorm:"column:id;is_primary"`
	GrandparentId int64    `gorm:"column:grandparent_id"`
	Name          string   `gorm:"column:name"`
	Children      []*Child `gorm:"foreignKey:ParentId"`
	Grandparent   *Grandparent
}

func (r *Parent) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForParent.RLock()
	if client.colIdxTabForParent == nil {
		client.rwlockForParent.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForParent,
			&client.rwlockForParent,
			rs,
			&client.colIdxTabForParent,
		)
		if err != nil {
			return err
		}
		client.rwlockForParent.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForParent

	scanTgts := make([]interface{}, len(client.colIdxTabForParent))
	for runIdx, genIdx := range client.colIdxTabForParent {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForParent[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForParent.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForParent.RLock()
		if len(client.colIdxTabForParent) != len(colNames) {
			client.rwlockForParent.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForParent,
				&client.rwlockForParent,
				rs,
				&client.colIdxTabForParent,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForParent.RUnlock()
			return err
		}
	}

	return nil
}

type nullableScanTgtsForParent struct {
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForParent = [...]func(*Parent, *nullableScanTgtsForParent) interface{}{
	func(
		r *Parent,
		nullableTgts *nullableScanTgtsForParent,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Parent,
		nullableTgts *nullableScanTgtsForParent,
	) interface{} {
		return &(r.GrandparentId)
	},
	func(
		r *Parent,
		nullableTgts *nullableScanTgtsForParent,
	) interface{} {
		return &(r.Name)
	},
}

var genTimeColIdxTabForParent map[string]int = map[string]int{
	`id`:             0,
	`grandparent_id`: 1,
	`name`:           2,
}

type Grandparent struct {
	Id                 int64     `gorm:"column:id;is_primary"`
	Name               string    `gorm:"column:name"`
	FavoriteGrandkidId *int64    `gorm:"column:favorite_grandkid_id"`
	Parents            []*Parent `gorm:"foreignKey:GrandparentId"`
	FavoriteGrandkid   *Child
}

func (r *Grandparent) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForGrandparent.RLock()
	if client.colIdxTabForGrandparent == nil {
		client.rwlockForGrandparent.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForGrandparent,
			&client.rwlockForGrandparent,
			rs,
			&client.colIdxTabForGrandparent,
		)
		if err != nil {
			return err
		}
		client.rwlockForGrandparent.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForGrandparent

	scanTgts := make([]interface{}, len(client.colIdxTabForGrandparent))
	for runIdx, genIdx := range client.colIdxTabForGrandparent {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForGrandparent[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForGrandparent.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForGrandparent.RLock()
		if len(client.colIdxTabForGrandparent) != len(colNames) {
			client.rwlockForGrandparent.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForGrandparent,
				&client.rwlockForGrandparent,
				rs,
				&client.colIdxTabForGrandparent,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForGrandparent.RUnlock()
			return err
		}
	}
	r.FavoriteGrandkidId = convertNullInt64(nullableTgts.scanFavoriteGrandkidId)

	return nil
}

type nullableScanTgtsForGrandparent struct {
	scanFavoriteGrandkidId sql.NullInt64
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForGrandparent = [...]func(*Grandparent, *nullableScanTgtsForGrandparent) interface{}{
	func(
		r *Grandparent,
		nullableTgts *nullableScanTgtsForGrandparent,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Grandparent,
		nullableTgts *nullableScanTgtsForGrandparent,
	) interface{} {
		return &(r.Name)
	},
	func(
		r *Grandparent,
		nullableTgts *nullableScanTgtsForGrandparent,
	) interface{} {
		return &(nullableTgts.scanFavoriteGrandkidId)
	},
}

var genTimeColIdxTabForGrandparent map[string]int = map[string]int{
	`id`:                   0,
	`name`:                 1,
	`favorite_grandkid_id`: 2,
}

type Child struct {
	Id                  int64          `gorm:"column:id;is_primary"`
	ParentId            int64          `gorm:"column:parent_id"`
	Name                string         `gorm:"column:name"`
	DarlingGrandparents []*Grandparent `gorm:"foreignKey:FavoriteGrandkidId"`
	Parent              *Parent
}

func (r *Child) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForChild.RLock()
	if client.colIdxTabForChild == nil {
		client.rwlockForChild.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForChild,
			&client.rwlockForChild,
			rs,
			&client.colIdxTabForChild,
		)
		if err != nil {
			return err
		}
		client.rwlockForChild.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForChild

	scanTgts := make([]interface{}, len(client.colIdxTabForChild))
	for runIdx, genIdx := range client.colIdxTabForChild {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForChild[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForChild.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForChild.RLock()
		if len(client.colIdxTabForChild) != len(colNames) {
			client.rwlockForChild.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForChild,
				&client.rwlockForChild,
				rs,
				&client.colIdxTabForChild,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForChild.RUnlock()
			return err
		}
	}

	return nil
}

type nullableScanTgtsForChild struct {
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForChild = [...]func(*Child, *nullableScanTgtsForChild) interface{}{
	func(
		r *Child,
		nullableTgts *nullableScanTgtsForChild,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Child,
		nullableTgts *nullableScanTgtsForChild,
	) interface{} {
		return &(r.ParentId)
	},
	func(
		r *Child,
		nullableTgts *nullableScanTgtsForChild,
	) interface{} {
		return &(r.Name)
	},
}

var genTimeColIdxTabForChild map[string]int = map[string]int{
	`id`:        0,
	`parent_id`: 1,
	`name`:      2,
}
